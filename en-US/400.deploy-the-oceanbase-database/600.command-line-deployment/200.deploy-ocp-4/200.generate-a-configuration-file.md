# Generate a configuration file

Before the deployment of OceanBase Cloud Platform (OCP), you must use oat-cli, the command-line tool of OceanBase Admin Toolkit (OAT), to generate a configuration file template and modify the template as needed.

## Configure environment variables

### Description

You can execute an SSH connection by specifying environment variables. Non-root users and private keys are supported for the connection. For more information, see the help information in **<span>install.sh</span> -h**. Note that passwordless SSH logon is no longer supported. This is to improve security.

### Applicable versions

oat-cli V1.4.0 and later.

### Use init_obcluster_conf.sh to generate the configuration file

If the configuration file exists, the script obtains the values of the following environment variables: `SSH_AUTH`, `SSH_USER`, `SSH_PORT`, `SSH_PASSWORD`, and `SSH_KEY_FILE`.

Syntax for parameter setting:

```shell
export ssh_parameter = parameter_value

ssh_parameter:
  SSH_AUTH
 | SSH_USER
 | SSH_PORT
 | SSH_PASSWORD
 | SSH_KEY_FILE
```

Parameters:

* `SSH_AUTH`: the authentication mode. Default value: `password`. Valid values: `password` and `pubkey`.

* `SSH_USER`: the user. Default value: `root`. If a non-root user is specified, make sure that the user is authorized to run the `sudo bash` command and a password or the `/etc/sudoers` settings are not specified.

* `SSH_PORT`: the port number. Default value: `22`.

* `SSH_PASSWORD`: the password. No password is specified by default.

* `SSH_KEY_FILE`: the directory of the key file. Default value: `/root/.ssh/id_rsa`. This parameter takes effect only when `SSH_AUTH` is set to `pubkey`.

Example:

```shell
export SSH_AUTH = password
export SSH_USER = root
export SSH_PORT = 22
export SSH_PASSWORD = '******'
export SSH_KEY_FILE = /root/.ssh/id_rsa
```

## Single-node deployment

1. Log on as the root user to the server where OCP is deployed and run the following commands:

   ```javascript
   [root@hostname /]# cd /root/t-oceanbase-antman
   [root@hostname /root/t-oceanbase-antman]# bash init_obcluster_conf.sh
   ```

2. During mode selection, enter **1** for single-node deployment.

   The corresponding configuration file template is generated.

   Example:

   ```javascript
   ## obcluster.conf
   ##
   SINGLE_OCP_MODE=TRUE
   ################################ MUST CHANGE ACCORDING ENVIRONMENT ################################
   ############ Edit Machine IP and Password Of root/admin ############
   ZONE1_RS_IP=xxx.xxx.xxx.xxx
   OBSERVER01_ROOTPASS=rootpass
   OBSERVER01_ADMINPASS=adminpass
   SSH_PORT=22

   ############ Edit Configuration of Load Balance ############
   # lb_mode: dns/f5/none, default: dns for 3 ocp, none for 1 ocp
   lb_mode=none

   # Remaining content
   ...
   ```

3. Modify the configuration file template based on the comments.

   The following information needs to be modified:

   * You must enter the server IP address and the passwords of the root and admin users. For single-node deployment, you need to specify the information of only one server.

   * For single-node deployment, set `lb_mode` to `none` to disable load balancing.

   * Allocate resources to the Docker container based on the CPU and memory resources of the physical server.

   * You can run the `docker load -i <docker image>` command and the `docker images` command to obtain the version information of Docker containers of the OBServer, OBProxy, and OCP.

   * To deploy OceanBase Migration Service (OMS), enter the basic configuration of OMS, including the IP address of the OMS server and the version information of the OMS Docker container.

   * To deploy OceanBase Developer Center (ODC), enter the version information of the ODC Docker container.

## Deployment in three-node mode

1. Log on to the OCP server as the root user and run the following command:

   ```javascript
   bash init_obcluster_conf.sh
   ```

2. During mode selection, enter **3** for three-node deployment.

   The corresponding configuration file template is generated.

   Example:

   ```javascript
   ################################ MUST CHANGE ACCORDING ENVIRONMENT ################################
   ############ Edit Machine IP and Password Of root/admin ############
   ZONE1_RS_IP=xxx.xxx.xxx.xxx
   ZONE2_RS_IP=xxx.xxx.xxx.xxx
   ZONE3_RS_IP=xxx.xxx.xxx.xxx
   OBSERVER01_ROOTPASS=rootpass
   OBSERVER02_ROOTPASS=rootpass
   OBSERVER03_ROOTPASS=rootpass
   OBSERVER01_ADMINPASS=adminpass
   OBSERVER02_ADMINPASS=adminpass
   OBSERVER03_ADMINPASS=adminpass

   ############ Edit Configuration of Load Balance ############
   # lb_mode: dns/f5/none, default: dns for 3 ocp, none for 1 ocp
   lb_mode=dns

   # Remaining content
   ...
   ```

3. Modify the configuration file template based on the comments.

   The following information needs to be modified:

   * You must enter the server IP address and the passwords of the root and admin users. For three-node deployment, you must enter the information of three servers.

      * If you select `dns` for `lb_mode`, the domain name `oceanbase.com` is recommended by default. This domain name can be accessed only from OCP nodes. To access this domain name from other nodes, configure domain name resolution for these nodes. </br>As an example for description, `lb_mode` is set to `dns`.
      * If you select `F5` for `lb_mode`, you need to configure the virtual IP addresses (VIPs) and virtual port numbers of OBProxy and OCP. You need to apply for the VIPs and port numbers in advance.

   * Allocate resources to the Docker containers based on the CPU and memory resources of the physical servers.</br>
      Default specifications: 32C/128G (32 CPU cores and 128 GB of memory) for OBServer, 8C/16G (8 CPU cores and 16 GB of memory) for OCP, and 4C/12G (4 CPU cores and 12 GB of memory) for OBProxy.</br>
      If the physical server is provided based on the recommended minimum configuration, you can customize the server resources. The OBServer resources must be greater than 24C/100G (24 CPU cores and 100 GB of memory), the OCP resources must be greater than 4C/8G (4 CPU cores and 8 GB of memory), and OBProxy resources must be greater than 2C/10G (2 CPU cores and 10 GB of memory).

   * You can run the `docker load -i <docker image>` command and the `docker images` command to obtain the version information of Docker containers of the OBServer, OBProxy, and OCP.

   * To deploy OMS, enter the basic configuration of OMS, including the IP address of the OMS server and the version information of the OMS Docker container.

   * To deploy ODC, enter the version information of the ODC Docker container.

## Deployment in multi-zone mode

1. Check if the `obcluster.conf` file exists in the `/root/t-oceanbase-antman/` directory.

   * If yes, skip to Step 4.

   * Otherwise, proceed to the next step.

2. Log on as the root user to the server where OCP is deployed and run the following commands:

   ```javascript
   [root@hostname /]# cd /root/t-oceanbase-antman/
   [root@hostname clonescripts]# bash init_obcluster_conf.sh
   ```

3. During mode selection, enter **3** for multi-node deployment.

   The corresponding configuration file template is generated.

   Example:

   ```javascript
   ##################  OCP multi-zone configurations  ######################
   OCP_MAZ_ENABLED=TRUE                                 #If multi-zone mode is enabled and no global VIP is available, the configured OCP_VIP and OBPROXY_VIP values can be changed to the VIP of the primary zone or the IP address of any OCP node.
   OCP_MAZ_AZ_NAME_LIST=(az1 az1 az2)                #The zone names that you specified for az_name for OCP 1, OCP 2, and OCP 3.
   OCP_MAZ_OCP_VIP_LIST=(192.168.0.1 192.168.0.2 192.168.0.3)   #The IP addresses that you specified for site-url for OCP 1, OCP 2, and OCP 3.
   OCP_MAZ_OCP_VPORT_LIST=(8080 8080 8080)      #The port numbers that you specified for site-url for OCP 1, OCP 2, and OCP 3.
   OCP_MAZ_METAPROXY_VIP_LIST=(192.168.0.1 192.168.0.2 192.168.0.3)  #The IP addresses of MetaDB for OCP 1, OCP 2, and OCP 3.
   OCP_MAZ_METAPROXY_VPORT_LIST=(2883 2883 2883)         #The port numbers of MetaDB for OCP 1, OCP 2, and OCP 3.
   ```

4. When you deploy OCP in multi-zone mode, configure the parameters in the "OCP multi-zone configurations" section.

   The following information needs to be modified:

   > **Note**
   >
   > By default, in the template for multi-zone OCP deployment, three zones are configured. You can add or delete the number of values for related parameters as needed. For example, if you want to deploy the OCP cluster across two zones, set `OCP_MAZ_AZ_NAME_LIST=(az1 az2)`.

   * OCP_MAZ_ENABLED: indicates whether multi-zone mode is enabled. Default value: `FALSE`. Set the value to `TRUE` when you need to enable multi-zone mode.

   * OCP_MAZ_AZ_NAME_LIST: specifies the zone names of the OCP nodes, for example, (az1 az2 az3). The zone names of different OCP nodes can be the same, for example, (az1 az1 az2).

   * OCP_MAZ_OCP_VIP_LIST: specifies the server addresses of the OCP nodes, namely, the host part of SiteUrl, for example, (10.1.1.1 10.1.1.2 10.1.1.3).

   * OCP_MAZ_OCP_VPORT_LIST: specifies the server ports of the OCP nodes, namely, the part of SiteUrl for the port, for example, (80 80 80).

   * OCP_MAZ_METAPROXY_VIP_LIST: specifies the IP addresses of the OCP nodes for accessing the MetaDB.

   * OCP_MAZ_METAPROXY_VPORT_LIST: specifies the port numbers of the OCP nodes for accessing the MetaDB.
