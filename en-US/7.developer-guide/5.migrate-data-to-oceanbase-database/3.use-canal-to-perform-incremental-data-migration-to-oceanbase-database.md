Use Canal to perform incremental data migration to OceanBase Database 
==========================================================================================



This topic shows you how to perform incremental data migration to OceanBase Database by using Canal. Canal is an open source component that subscribes to and consumes the incremental data in MySQL Binlog. It parses incremental log data of a MySQL database and can be used for data synchronization. For more information, visit the [Canal repository](https://github.com/oceanbase/canal) on GitHub. 

Architecture 
---------------------------------

Canal works with the following four components:

* `Canal Deployer`: the Canal component that serves as a server and converts the binlogs to CanalEntry data.

  

* `Canal Admin`: the configuration administrator of Canal. It provides a web page for you to manage the Canal Deployer.

  

* `Canal Adapter`: the client adapter of Canal. It parses the CanalEntry data and synchronizes the incremental changes to the destination database.

  

* `Canal Example`: the client example of Canal. You can modify the sample code as needed to implement your consumption logic.

  




![Canal architecture](https://help-static-aliyun-doc.aliyuncs.com/assets/img/en-US/1915623461/p369312.png)

The preceding figure shows the sample architecture of Canal, which consists of the following parts:

* `mariadb`: the source database.

  

* `canal-admin`: Optional. The configuration administrator of Canal used to deploy the canal-server.

  

* `canal-server`: the Canal Deployer software.

  

* `adapter`: the Canal Adapter software.

  

* `oceanbase`: the destination database. In this case, it is a MySQL tenant in OceanBase Database.

  




### Canal Deployer 

In OceanBase Database, Canal Deployer provides services by using Canal servers and instances. A Canal server can have multiple instances, and an instance represents a data synchronization channel. 

A Canal instance is created by a running Spring. The configuration information of the Canal instance is specified in the `canal.properties` file in the conf/ directory. Canal provides several configuration files that are stored in the `conf/spring` directory. You can directly use these configuration files. 

After a Canal instance parses binlogs into the CanalEntry data, it stores the CanalEntry data in the memory for later consumption. Canal provides two data consumption modes:

* TCP mode: the destination database directly connects to Canal for data consumption.

  

* MQ mode: the data in the Canal memory is written to a message queue (MQ), and the destination database connects to the MQ for data consumption.

  




Canal has the following offsets:

* Parsing offsets: record the process of converting binlogs into CanalEntry data. These offsets are managed by LogPositionManager.

  

* Consumption offsets: managed by MetaManager.

  




The information of these two types of offsets is also specified in the `spring.xml` file of the Canal instance.

### Canal Adapter 

Canal Adapter consumes the CanalEntry data and writes it to the corresponding destination container. Similar to Canal Deployer, Canal Adapter also provides instances. Canal Adapter is started by the Adapter launcher and generates instances based on the configurations that you specified. The instances read the CanalEntry data and write it to the destination database.


Deployment example 
---------------------------------------

### Prepare a MySQL database 

This example shows you how to prepare MariaDB, a self-managed MySQL database. You can run the following command to install MariaDB: 

```unknow
yum install mariadb mariadb-server
```



* You must first enable Binlog writing and set the `binlog-format` parameter to ROW. The following example shows you how to configure the `my.cnf` file:

  ```unknow
  [mysqld]
  log-bin=mysql-bin # Enable the Binlog.
  binlog-format=ROW # Set the binglog format to ROW.
  server_id=1 # The server ID must be defined for the configuration of MySQL replication. It must be different from the slaveId of Canal.
  ```

  




<!-- -->

* Run the following commands to create a Canal user for connection with the MySQL database and grant the `MySQL slave` permissions to the Canal user. If you already have a Canal user, directly run the `grant` command. 

  ```unknow
  CREATE USER canal IDENTIFIED BY 'canal';  
  GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';
  -- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;
  FLUSH PRIVILEGES;
  ```



### Deploy Canal Deployer 

* Run the following command to download Canal Deployer. You can also click [Download](https://github.com/alibaba/canal/releases) to go to the download page of Canal Deployer.

  ```bash
  wget https://github.com/alibaba/canal/releases/download/canal-1.1.5/canal.deployer-1.1.5.tar.gz
  ```

  




<!-- -->

* Run the following command to extract files to the specified directory:

  ```bash
  mkdir ~/canal && tar zxvf canal.deployer-1.1.5.tar.gz  -C ~/canal
  ```

  




<!-- -->

* Modify the configurations

  Use the default configuration files `conf/canal.properties` and `conf/example/instance.properties`. These configuration files are provided to create a default instance named `example`. You need to modify the database connection address, user name, and password of the `example` instance. The following sample code shows you how to modify the configuration file: 

  ```unknow
  vi conf/example/instance.properties
  
  # mysql serverId
  canal.instance.mysql.slaveId = 1234
  # Specify the position information of your database.
  canal.instance.master.address = 127.0.0.1:3306 
  canal.instance.master.journal.name = 
  canal.instance.master.position = 
  canal.instance.master.timestamp = 
  #canal.instance.standby.address =
  #canal.instance.standby.journal.name =
  #canal.instance.standby.position =
  #canal.instance.standby.timestamp =
  # Specify the username and password of your database.
  canal.instance.dbUsername = canal  
  canal.instance.dbPassword = canal
  canal.instance.defaultDatabaseName =
  canal.instance.connectionCharset = UTF-8
  #table regex
  canal.instance.filter.regex = .\*\\\\..\*
  ```

  

  The `canal.instance.connectionCharset` parameter specifies the Java encoding type corresponding to the database encoding method. Valid values: `UTF-8`, `GBK`, and `ISO-8859-1`. If the system has only one CPU core, set the `canal.instance.parser.parallel` parameter to `false`.
  



* Start Canal Server

  You can run the following command to start Canal Server after you modify the configuration files: 

  ```unknow
  sh bin/startup.sh
  ```

 

* View server logs

  You can view the server logs in the command-line window by running the following command: 

  ```unknow
  vi logs/canal/canal.log
  ```

  

* View instance logs

  You can view the instance logs either in Canal Admin, or in the command-line window by running the following commands: 

  ```unknow
  tail -f logs/canal/canal.log
  tail -f logs/example/example.log
  tail -f logs/mariadb/mariadb.log
  ```

  

* Run the following command to stop the service:

  ```unknow
  sh bin/stop.sh
  ```

  




Deploy the RDB adapter 
-------------------------------------------

Canal Adapter supports multiple containers. For OceanBase Community Edition, the Canal Adapter uses the RDB module. The destination container can be a MySQL database or an OceanBase database. In this example, the destination container is an OceanBase database. 

You need to perform the following steps and manually deploy Canal Adapter: 

* Modify the configuration file `application.yml` of the launcher. 

  Set the `mode` type of the adapter source to `tcp`. Specify the `canal.tcp` properties, including the IP address and port of `canal server` and the username and password for database connection. Then, specify the connection information of the adapter destination. 

  ```bash
  mode: tcp #tcp kafka rocketMQ rabbitMQ
    flatMessage: true
    zookeeperHosts:
    syncBatchSize: 1000
    retries: 0
    timeout:
    accessKey:
    secretKey:
    consumerProperties:
     # canal tcp consumer
      canal.tcp.server.host: 127.0.0.1:11111
      canal.tcp.zookeeper.hosts:
      canal.tcp.batch.size: 500
      canal.tcp.username: tpch
      canal.tcp.password: Dg0gIexJAV
    canalAdapters:
    - instance: example # canal instance Name or mq topic name
      groups:
      - groupId: g1
        outerAdapters:
      - name: logger
        - name: rdb
          key: obmysql
          properties:
            jdbc.driverClassName: com.mysql.jdbc.Driver
            jdbc.url: jdbc:mysql://127.0.0.1:2883/tpch?useUnicode=true
            jdbc.username: t****@obmysql#obdemo
            jdbc.password: Dg0gIe****   
  ```

  

  Parameter description:
  * `instance`: the name of the source instance specified during the deployment of Canal Deployer, which is `example`.

    
  
  * `key`: a custom parameter. The value will be used later.

    
  
  * `jdbc`: indicates how the destination OceanBase database is connected to the source MySQL database. You can use the MySQL driver.

    
  

  




<!-- -->

* Modify the RDB mapping file

  You need to modify the `mytest_user.yml` file in the conf/rdb/ directory. 

  You can configure table-based or full-database mapping. The following example shows how to configure full-database mapping: 

  ```bash
  [root@obce00 adapter]# cat conf/rdb/mytest_user.yml
  #dataSourceKey: defaultDS
  #destination: example
  #groupId: g1
  #outerAdapterKey: mysql1
  #concurrent: true
  #dbMapping:
  #  database: mytest
  #  table: user
  #  targetTable: mytest2.user
  #  targetPk:
  #    id: id
  ##  mapAll: true
  #  targetColumns:
  #    id:
  #    name:
  #    role_id:
  #    c_time:
  #    test1:
  #  etlCondition: "where c_time>={}"
  #  commitBatch: 3000 # The size of batch commit.
  # Mirror schema synchronize config
  dataSourceKey: defaultDS
  destination: mariadb
  groupId: g1
  outerAdapterKey: obmysql
  concurrent: true
  dbMapping:
    mirrorDb: true
    database: tpch
    commitBatch: 1000
  ```

  

  The `destination` parameter indicates the name of the Canal instance. The `outerAdapterKey` parameter is the user-defined `key`. The `mirrorDb` parameter indicates that the database level DDL and DML operations of the source database are mirrored to the destination database. 

  The type of imported data depends on the metatype of the destination table. Data types are automatically converted.
  

* Start RDB

  If you use the driver of OceanBase Database for the destination database, place the driver package in the `lib` folder. 

  Run the following command to start the `canal-adapter` launcher: 

  ```bash
  bin/startup.sh
  ```

  

  Modify the data of the `mysql mytest.user` table to verify the configuration. The modification will be automatically synchronized to the `MYTEST.TB_USER` table of the MySQL database. The logs of DML operations will be displayed.
  

* Run the following command to stop RDB:

  ```bash
  bin/stop.sh
  ```

  

* Run the following command to view RDB logs:

  ```bash
  tail -f logs/adapter/adapter.log
  2021-12-09 09:56:04.148 [pool-6-thread-1] DEBUG c.a.o.canal.client.adapter.rdb.service.RdbSyncService - DML: {"data":{"s_suppkey":99995,"s_name":null,"s_address":null,"s_nationkey":null,"s_phone":null,"s_acctbal":null,"s_comment":null},"database":"tpch","destination":"mariadb","old":null,"table":"supplier2","type":"INSERT"}
  2021-12-09 09:56:04.149 [pool-6-thread-1] DEBUG c.a.o.canal.client.adapter.rdb.service.RdbSyncService - DML: {"data":{"s_suppkey":99998,"s_name":null,"s_address":null,"s_nationkey":null,"s_phone":null,"s_acctbal":null,"s_comment":null},"database":"tpch","destination":"mariadb","old":null,"table":"supplier2","type":"INSERT"}
  2021-12-09 10:13:35.915 [Thread-3] INFO  c.a.o.canal.client.adapter.rdb.monitor.RdbConfigMonitor - Change a rdb mapping config: mytest_user.yml of canal adapter
  ```

  




Perform the synchronization test 
-----------------------------------------------------

You can perform DML and DDL operations in the source MySQL database named `tpch`, and check whether the modifications can be synchronized to the destination database. Note the following synchronization restrictions: 

* The source table must have a primary key. Otherwise, if a record is deleted from the source table, the synchronized table in the destination is fully deleted.

  

* The CREATE TABLE and CREATE COLUMN DDL operations can be synchronized. However, due to the restrictions on the MySQL tenant in OceanBase Database, a primary key added after a table is created, or modifications to the column type, such as Numeric, String, and Date/Time, cannot be synchronized.

  




